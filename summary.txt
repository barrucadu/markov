MarkovState: tracks moment-to-moment of running generator
	__init__: self.markov is a chain/data store, 
		self.generator is a function with state
		both start null.
	load:	take filename, create a Markov instance, 
		save it to self.markov, 
		load the file into that instance
	dump:	take filename, save the Markov self.markov to that file
	train:	take n (prefix length), stream (file or STDIN),
			and setting for noparagraphs
		Turn the file into tokens, 
		create Markov instance of prefix-length n,
		save to self.markov and train it on the token stream,
		clear generator
	generate: take chunks (how much to generate), 
			random seed (defaults to systime), 
			prob (chance to choose random token, default 0), 
			offset (number of initial tokens to discard),
			cln (tokens to clear after a clause, default 0),
			startf (lambda for first token to use, default true),
			endchunkf (lambda for last token to use, default true),
			kill (number of tokens to drop off the end),
			prefix (start out with these tokens before generating),
		set seed to systime as int if not defined (and print it),
		reset markov(seed, prob, prefix, cln),
		pass over offset instances of next(self.markov),
		continue until the next token meets the startf predicate,
		define a generator function gen(n)
			out is an empty array
			shove next(self.markov) into out
			if the token satisfies endchunkf, decrement n
			return out joined with ' '
		assign this to self.generator
		return n chunks from the generator
	more: take chunks (default 1) and generate more from the
		pre-existing generator

Markov: stores and structures the data
	__init__: takes n (prefix size), default 3,
		set self.n to n, self.p to 0, self.seed to null,
		self.data to empty hash, self.cln to n
	set_cln: takes cln (tokens to clear after a clause)
	train: takes token stream of training data,
		set prev to empty, iterate through stream as token,
			create a list of suffixes of prev and iterate 
				through it as pprev,
			for each pprev, if it is not in self.data, initialize
				it to [0, {}] (no occurences, no successors),
			then add the current token to the hash of the entry,
				adding it as a key if necessary,
			and increment the total count and token-specific count,
		then (in the each-token loop) append this token to prev,
		remove the head of prev if it's too long,
		and repeat until the token stream is empty
	load: takes filename, import model from filename,
		parse import to get n, self.data (prefix-length, hash),
		set self.n to min (n, self.n) and print if changed,
		do this under try-except for safety
	dump: takes filename, stores (self, self.data) to filename,
		do this under try-except for safety
	reset: takes seed (new random seed), 
			prob (chance to choose random token), 
			prev (start out with these tokens before generating),
			cln (tokens to clear after a clause),
		set everything to new values,
		initialize the RNG with the seed
	__iter__: return self (iterator of a Markov is itself, it is iterable)
	__next__: pick an key for self.data,
		with probability self.p this will be the empty key (),
		else it will be self.prev,
		set next to self._choose(self.data[that key]),
			 - on any exception retry with ()
		append next to self.prev,
		if self.prev is longer than self.n, drop the head,
		if the end of next is a clause-ender (.?! or \n, depending),
			keep only the last self.cln tokens in self.prev
		return next
	_choose: (private) takes a two-element array freqdict, 
		parses it to total, choices,
			(i.e. sum of all freqs, hash of all successors)
		generate a random idx up to total,
		then index through the choices.items as (token, freq),
		and either return token or subtract freq from idx
